{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Preprocessing of Movie Metadata\n",
    "\n",
    "Data sourced from MovieLens (https://grouplens.org/datasets/movielens/1m/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['adult', 'belongs_to_collection', 'budget', 'genres', 'homepage', 'id',\n",
      "       'imdb_id', 'original_language', 'original_title', 'overview',\n",
      "       'popularity', 'poster_path', 'production_companies',\n",
      "       'production_countries', 'release_date', 'revenue', 'runtime',\n",
      "       'spoken_languages', 'status', 'tagline', 'title', 'video',\n",
      "       'vote_average', 'vote_count'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./the-movies-dataset/movies_metadata.csv',low_memory=False)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmdbId to movieId dictionary, first 2 pairs: \n",
      "{862.0: 1, 8844.0: 2}\n"
     ]
    }
   ],
   "source": [
    "# We have movie embeddings from a neural network trained on user ratings but they use a different ID system\n",
    "# 'links.csv' contains the mappings from the ID system used in 'movies_metadata' to that of the embeddings\n",
    "# we create a dictionary to map between the two\n",
    "import pickle\n",
    "with open('G:/My Drive/DublinAI/Mini Projects/chatbot/nn/embeddings_smaller', 'rb') as file:\n",
    "    embed, movie_to_index = pickle.load(file)\n",
    "mappings = pd.read_csv('./the-movies-dataset/links.csv',low_memory=False)\n",
    "mappings = mappings.drop_duplicates(subset=['tmdbId'],keep='first')\n",
    "mappings.set_index('tmdbId',inplace=True)\n",
    "to_movieId = mappings.to_dict()['movieId'] \n",
    "print('tmdbId to movieId dictionary, first 2 pairs: ')\n",
    "first2pairs = {k: to_movieId[k] for k in list(to_movieId)[:2]}\n",
    "print(first2pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "title": "Data Munging"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text clean up -\n",
      "Tagline before: Roll the dice and unleash the excitement!\n",
      "Tagline after: roll the dice and unleash the excitement\n",
      "Genres before: [{'id': 12, 'name': 'Adventure'}, {'id': 14, 'name': 'Fantasy'}, {'id': 10751, 'name': 'Family'}]\n",
      "Genres after: Adventure, Fantasy, Family\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import ast   \n",
    "def clean_text(text):\n",
    "    token = re.sub(r'[\\^\\\\,@\\‘?!\\.$%_:\\-“’“”]', '', text, flags=re.I)\n",
    "    return token\n",
    "\n",
    "# drop fields that are not relevant for our application \n",
    "df = df[df['adult'] == 'FALSE']\n",
    "df = df.drop(['adult','homepage','budget','runtime','release_date','original_language','production_countries','production_companies','spoken_languages','video','revenue','status','vote_count'],axis=1)\n",
    "df = df.dropna(subset=['imdb_id','poster_path'])\n",
    "\n",
    "# clean up text\n",
    "print('Text clean up -')\n",
    "print('Tagline before: ' + str(df['tagline'][1]))\n",
    "df['tagline'] = df['tagline'].apply(lambda x: clean_text(str(x)).lower())\n",
    "print('Tagline after: ' + str(df['tagline'][1]))\n",
    "df['title'] = df['title'].apply(lambda x: clean_text(str(x)).lower())\n",
    "df['original_title'] = df['original_title'].apply(lambda x: clean_text(str(x)).lower())\n",
    "df['overview'] = df['overview'].apply(lambda x: clean_text(str(x)).lower())\n",
    "print('Genres before: ' + str(df['genres'][1]))\n",
    "df['genres'] = df['genres'].apply(lambda x: ast.literal_eval(x)) #make into dictionary\n",
    "df['genres'] = df['genres'].apply(lambda x: ', '.join([d['name'] for d in x]))\n",
    "print('Genres after: ' + str(df['genres'][1]))\n",
    "df['imdbURL'] = 'https://www.imdb.com/title/' + df['imdb_id'] + '/'\n",
    "df['tmdbURL'] = 'https://www.themoviedb.org/movie/' + df['id']\n",
    "df['ImageURL'] = 'https://image.tmdb.org/t/p/w92' + df['poster_path']\n",
    "#ratings = pd.read_csv('./the-movies-dataset/ratings.csv',low_memory=False)\n",
    "df['overview'] = df['overview'].fillna('')\n",
    "df['genres'] = df['genres'].fillna('') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "add column of mapping to other dataset, drop movies where we don't have embeddings"
   },
   "outputs": [],
   "source": [
    "# Add column of mapped IDs to dataframe\n",
    "df = df.astype({'id':'int64'})\n",
    "df['movieId'] = df['id'].map(to_movieId)\n",
    "df['newId'] = df['movieId'].map(movie_to_index)\n",
    "df = df.dropna(subset=['newId'])\n",
    "df = df.reset_index()\n",
    "df = df.drop(['index'],axis=1)\n",
    "a = df['belongs_to_collection'][df['belongs_to_collection'].notnull()]\n",
    "indices = list(a.index)\n",
    "for i in indices:\n",
    "    b = str(a[i]).split(\", 'poster_path'\")\n",
    "    df['belongs_to_collection'][i]=ast.literal_eval(b[0]+'}').get('id')\n",
    "\n",
    "df.to_csv('./the-movies-dataset/df_prep.csv')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
